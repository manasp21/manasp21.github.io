{
  "https://github.com/manasp21/PsiAnimator-MCP": {
    "name": "PsiAnimator-MCP",
    "full_name": "manasp21/PsiAnimator-MCP",
    "description": "No description available",
    "readme_description": "Quantum Physics Simulation and Animation Server A Model Context Protocol (MCP) server that integrates QuTip (Quantum Toolbox in Python) for quantum physics computations with Manim (Mathematical Ani...",
    "language": "Python",
    "stars": 0,
    "forks": 0,
    "watchers": 0,
    "open_issues": 0,
    "topics": [],
    "homepage": null,
    "license": "MIT License",
    "created_at": "2025-06-24T10:40:51Z",
    "updated_at": "2025-06-24T11:37:02Z",
    "pushed_at": "2025-06-24T11:36:59Z",
    "size": 0,
    "default_branch": "main",
    "html_url": "https://github.com/manasp21/PsiAnimator-MCP",
    "clone_url": "https://github.com/manasp21/PsiAnimator-MCP.git",
    "ssh_url": "git@github.com:manasp21/PsiAnimator-MCP.git",
    "readme_content": "# PsiAnimator-MCP\n\n**Quantum Physics Simulation and Animation Server**\n\nA Model Context Protocol (MCP) server that integrates [QuTip](https://qutip.org/) (Quantum Toolbox in Python) for quantum physics computations with [Manim](https://www.manim.community/) (Mathematical Animation Engine) for visualization.\n\n## Features\n\n- 🔬 **Comprehensive Quantum Physics**: State management, time evolution, measurements\n- 🎬 **Beautiful Animations**: Publication-quality visualizations using Manim  \n- 🔌 **MCP Integration**: Easy integration with MCP-compatible clients\n- 🧮 **Scientific Computing**: Built on NumPy, SciPy, and QuTip\n- 📊 **Interactive Visualizations**: Bloch spheres, Wigner functions, state tomography\n- 🎓 **Educational Tools**: Perfect for quantum mechanics education and research\n\n## Quick Start\n\n### Installation\n\n```bash\npip install psianimator-mcp\n```\n\n### Development Installation\n\n```bash\ngit clone https://github.com/psianimator/psianimator-mcp.git\ncd psianimator-mcp\npip install -e \".[dev]\"\n```\n\n### Usage\n\nStart the MCP server:\n\n```bash\npsianimator-mcp\n```\n\n## MCP Tools\n\nPsiAnimator-MCP provides six core MCP tools:\n\n1. **`create_quantum_state`** - Create pure/mixed quantum states\n2. **`evolve_quantum_system`** - Time evolution with various solvers  \n3. **`measure_observable`** - Quantum measurements and expectation values\n4. **`animate_quantum_process`** - Generate Manim animations\n5. **`quantum_gate_sequence`** - Apply gate sequences with visualization\n6. **`calculate_entanglement`** - Compute entanglement measures\n\n## Requirements\n\n- Python ≥ 3.9\n- QuTip ≥ 4.7.0\n- Manim ≥ 0.18.0  \n- MCP ≥ 1.0.0\n\n## Documentation\n\nFull documentation is available at [psianimator-mcp.readthedocs.io](https://psianimator-mcp.readthedocs.io)\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n## Contributing\n\nContributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.",
    "cached_at": 1750765116.583637
  },
  "https://github.com/manasp21/Coheron": {
    "name": "Coheron",
    "full_name": "manasp21/Coheron",
    "description": "An Evolutionary AI System for Quantum Optics",
    "readme_description": "An evolutionary AI system for breakthrough quantum optics research discovery Inspired by AlphaEvolve, this system uses advanced language models to generate, evaluate, and evolve quantum optics rese...",
    "language": "Python",
    "stars": 0,
    "forks": 0,
    "watchers": 0,
    "open_issues": 0,
    "topics": [],
    "homepage": null,
    "license": "MIT License",
    "created_at": "2025-06-22T16:08:31Z",
    "updated_at": "2025-06-24T11:33:30Z",
    "pushed_at": "2025-06-24T11:33:27Z",
    "size": 565,
    "default_branch": "main",
    "html_url": "https://github.com/manasp21/Coheron",
    "clone_url": "https://github.com/manasp21/Coheron.git",
    "ssh_url": "git@github.com:manasp21/Coheron.git",
    "readme_content": "# Coheron\n\n**An evolutionary AI system for breakthrough quantum optics research discovery**\n\nInspired by AlphaEvolve, this system uses advanced language models to generate, evaluate, and evolve quantum optics research solutions through physics-aware evaluation and evolutionary algorithms.\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![OpenRouter](https://img.shields.io/badge/OpenRouter-Compatible-green.svg)](https://openrouter.ai/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n## 🌟 Features\n\n- **🧬 Evolutionary Research Discovery**: Inspired by AlphaEvolve architecture for systematic research evolution\n- **🔬 Physics-Aware Evaluation**: Rigorous evaluation against analytical benchmarks and experimental feasibility\n- **🔄 Flexible Model Switching**: Easy switching between DeepSeek, Claude, GPT-4, and other models via OpenRouter\n- **📊 Comprehensive Analytics**: Track research evolution, breakthrough discoveries, and model performance\n- **🎯 Specialized Categories**: Focus on cavity QED, squeezed light, photon blockade, quantum metrology, and optomechanics\n- **💾 Research Database**: SQLite-based storage for evolution tracking and lineage analysis\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n- Python 3.9 or higher\n- OpenRouter API key ([Get one here](https://openrouter.ai/keys))\n\n### Installation\n\n1. **Clone the repository**\n   ```bash\n   git clone <repository-url>\n   cd Coheron\n   ```\n\n2. **Install dependencies**\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **Set up environment**\n   ```bash\n   cp .env.template .env\n   # Edit .env and add your OpenRouter API key\n   export OPENROUTER_API_KEY=\"your-api-key-here\"\n   ```\n\n4. **Run your first evolution**\n   ```bash\n   python src/main.py evolve --generations 10\n   ```\n\n## 📖 Usage\n\n### Basic Commands\n\n```bash\n# Run research evolution (default: DeepSeek R1 free)\npython src/main.py evolve --generations 20\n\n# Switch to a different model\npython src/main.py evolve --model \"anthropic/claude-3.5-sonnet\" --generations 15\n\n# Focus on specific research category\npython src/main.py evolve --category cavity_qed --generations 25\n\n# Evaluate research content\npython src/main.py evaluate --content \"Design a cavity QED system...\" --category cavity_qed\n\n# Analyze results and generate plots\npython src/main.py analyze --database --plots\n\n# Test system components\npython src/main.py test --full\n\n# Benchmark different models\npython src/main.py benchmark --compare-models\n```\n\n### Advanced Usage\n\n#### Custom Evolution Parameters\n```bash\npython src/main.py evolve \\\n  --generations 50 \\\n  --population 15 \\\n  --model \"deepseek/deepseek-r1\" \\\n  --output-dir custom_results \\\n  --save-interval 3\n```\n\n#### Detailed Evaluation\n```bash\npython src/main.py evaluate \\\n  --content research_paper.txt \\\n  --category quantum_metrology \\\n  --detailed \\\n  --save-result evaluation_results.json\n```\n\n#### Database Analysis\n```bash\npython src/main.py analyze \\\n  --database \\\n  --category squeezed_light \\\n  --plots \\\n  --export analysis_export.json\n```\n\n## 🏗️ Architecture\n\n### Core Components\n\n```\nCoheron/\n├── src/\n│   ├── main.py                 # CLI interface and application entry\n│   ├── evolution_controller.py # Main evolution loop (AlphaEvolve-inspired)\n│   ├── llm_interface.py        # OpenRouter integration with model switching\n│   ├── research_generator.py   # Quantum research prompt generation\n│   ├── evaluator.py            # Physics-aware evaluation system\n│   ├── database.py             # Research storage and tracking\n│   └── utils.py                # Utility functions and helpers\n├── config/\n│   ├── config.yaml             # Model and system configuration\n│   ├── prompts.yaml            # Research prompt templates\n│   └── evaluation_criteria.yaml # Scoring rubrics and benchmarks\n├── data/\n│   ├── seed_research.json      # Initial high-quality examples\n│   ├── benchmarks.json         # Analytical solution benchmarks\n│   └── research_history.db     # Evolution tracking database\n└── results/                    # Generated results and analysis\n```\n\n### Evolution Process\n\n1. **Initialization**: Load seed research examples and generate initial population\n2. **Generation Loop**: \n   - Generate mutations and crossovers from elite solutions\n   - Create exploratory solutions for novelty\n   - Evaluate all candidates using physics-aware scoring\n   - Select best solutions for next generation\n3. **Analysis**: Track progress, identify breakthroughs, and export results\n\n## 🎯 Research Categories\n\n### Cavity QED\n- Single atom strong coupling\n- Collective effects and superradiance\n- Quantum memory protocols\n- Deterministic photon generation\n\n### Squeezed Light\n- Parametric oscillator squeezing\n- Spin squeezing in atomic ensembles\n- Multimode entanglement\n- Gravitational wave detection enhancement\n\n### Photon Blockade\n- Kerr nonlinearity systems\n- Unconventional blockade mechanisms\n- Single photon sources\n- Photonic quantum gates\n\n### Quantum Metrology\n- N00N state interferometry\n- Atomic clock protocols\n- Quantum Fisher information\n- Heisenberg-limited sensing\n\n### Optomechanics\n- Ground state cooling\n- Quantum state transfer\n- Hybrid quantum systems\n- Quantum transduction\n\n## 🔧 Configuration\n\n### Model Switching\nChange models instantly by editing `config/config.yaml`:\n\n```yaml\ncurrent_model: \"deepseek/deepseek-r1-0528:free\"  # Free model\n# current_model: \"anthropic/claude-3.5-sonnet\"   # For complex analysis\n# current_model: \"openai/gpt-4-turbo\"            # For structured solutions\n```\n\n### Evolution Parameters\n```yaml\nevolution:\n  population_size: 10\n  max_generations: 50\n  mutation_rate: 0.3\n  crossover_rate: 0.7\n  elite_retention: 0.2\n```\n\n### Evaluation Weights\n```yaml\nevaluation:\n  weights:\n    feasibility: 0.25    # Physical realizability\n    mathematics: 0.30    # Mathematical correctness\n    novelty: 0.25        # Research novelty\n    performance: 0.20    # Performance metrics\n```\n\n## 📊 Evaluation System\n\nThe physics-aware evaluator scores research on four key dimensions:\n\n### 1. Feasibility (25%)\n- Energy conservation compliance\n- Fundamental physics limits\n- Realistic material properties\n- Experimental complexity assessment\n\n### 2. Mathematics (30%)\n- Analytical benchmark verification\n- Dimensional analysis consistency\n- Known solution comparison\n- Mathematical derivation correctness\n\n### 3. Novelty (25%)\n- Parameter regime exploration\n- Architectural innovation\n- Application breakthrough potential\n- Interdisciplinary connections\n\n### 4. Performance (20%)\n- Category-specific metrics\n- Experimental record comparison\n- Optimization potential\n- Scalability assessment\n\n## 🎨 Visualization and Analysis\n\nGenerate comprehensive analysis plots:\n\n```bash\n# Evolution progress tracking\npython src/main.py analyze --database --plots\n\n# Category performance comparison\npython src/main.py analyze --category-analysis\n\n# Model performance benchmarking\npython src/main.py benchmark --compare-models --models deepseek/deepseek-r1 anthropic/claude-3.5-sonnet\n```\n\n## 📈 Model Comparison\n\nEasily compare different models for quantum research:\n\n| Model | Physics Strength | Reasoning Style | Cost | Best For |\n|-------|-----------------|-----------------|------|----------|\n| DeepSeek R1 (Free) | High | Step-by-step | Free | Testing & exploration |\n| DeepSeek R1 (Paid) | High | Detailed | Low | Production use |\n| Claude 3.5 Sonnet | Very High | Analytical | Medium | Complex physics |\n| GPT-4 Turbo | High | Structured | High | Systematic analysis |\n| Gemini Pro | Medium | Creative | Low | Novel approaches |\n\n## 🤝 Integration Points\n\nThe system is designed with three main customization points:\n\n### 1. Research Prompts (`config/prompts.yaml`)\nAdd your domain-specific quantum optics research questions and exploration strategies.\n\n### 2. Evaluation System (`src/evaluator.py`)\nImplement your analytical solution benchmarks and scoring criteria.\n\n### 3. Seed Research (`data/seed_research.json`)\nProvide high-quality starting examples from your research area.\n\n## 🐛 Troubleshooting\n\n### Common Issues\n\n**API Key Error**\n```bash\n# Make sure your OpenRouter API key is set\nexport OPENROUTER_API_KEY=\"your-key-here\"\n# Or add it to your .env file\n```\n\n**Model Not Found**\n```bash\n# Check available models\npython src/main.py test --model\n# Update config with valid model name\n```\n\n**Database Issues**\n```bash\n# Reset database if corrupted\nrm data/research_history.db\n# System will create a new one automatically\n```\n\n**Memory Issues**\n```bash\n# Reduce population size for large models\npython src/main.py evolve --population 5 --generations 20\n```\n\n### Performance Optimization\n\n- Use free models for testing and paid models for production\n- Reduce population size and generations for faster iterations\n- Enable logging to monitor progress and debug issues\n- Use category focus to narrow search space\n\n## 📚 Examples\n\n### Example 1: Cavity QED Research\n```bash\npython src/main.py evolve \\\n  --category cavity_qed \\\n  --model \"deepseek/deepseek-r1-0528:free\" \\\n  --generations 15 \\\n  --population 8\n```\n\n### Example 2: Multi-Model Comparison\n```bash\n# Test with DeepSeek\npython src/main.py evolve --model \"deepseek/deepseek-r1-0528:free\" --generations 10\n\n# Test with Claude\npython src/main.py evolve --model \"anthropic/claude-3.5-sonnet\" --generations 10\n\n# Compare results\npython src/main.py analyze --database --export comparison.json\n```\n\n### Example 3: Custom Research Evaluation\n```bash\n# Evaluate your own research content\necho \"Design a cavity QED system with strong coupling...\" > my_research.txt\npython src/main.py evaluate \\\n  --content my_research.txt \\\n  --category cavity_qed \\\n  --detailed \\\n  --save-result my_evaluation.json\n```\n\n## 🛠️ Development\n\n### Running Tests\n```bash\n# Full system test\npython src/main.py test --full\n\n# Component-specific tests\npython src/main.py test --evaluator\npython src/main.py test --database\npython src/main.py test --model \"deepseek/deepseek-r1-0528:free\"\n```\n\n### Adding New Models\n1. Add model configuration to `config/config.yaml`\n2. Test with `python src/main.py test --model \"new-model-name\"`\n3. Benchmark with `python src/main.py benchmark --models \"new-model-name\"`\n\n### Extending Evaluation\n1. Add new physics categories to `config/prompts.yaml`\n2. Implement category-specific evaluation in `src/evaluator.py`\n3. Add benchmark problems to `data/benchmarks.json`\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 🙏 Acknowledgments\n\n- Inspired by the AlphaEvolve architecture for evolutionary AI discovery\n- Built on OpenRouter for flexible model access\n- Quantum optics benchmarks from leading research groups\n- Community contributions to quantum physics validation\n\n## 📞 Support\n\nFor questions, issues, or contributions:\n\n1. **Issues**: Open an issue on GitHub\n2. **Discussions**: Use GitHub Discussions for questions\n3. **Email**: Contact the development team\n4. **Documentation**: See `docs/` for detailed guides\n\n---\n\n**Ready to discover breakthrough quantum optics research? Start your evolution today!** 🚀\n\n```bash\nexport OPENROUTER_API_KEY=\"your-key-here\"\npython src/main.py evolve --generations 20\n```",
    "cached_at": 1750765152.499268
  },
  "https://github.com/manasp21/MagTrace": {
    "name": "MagTrace",
    "full_name": "manasp21/MagTrace",
    "description": "No description available",
    "readme_description": "Professional magnetic field analysis platform for research and industrial applications Author: Manas Pandey | Developed with Claude AI assistance",
    "language": "Python",
    "stars": 1,
    "forks": 0,
    "watchers": 1,
    "open_issues": 0,
    "topics": [],
    "homepage": null,
    "license": null,
    "created_at": "2025-06-05T05:45:52Z",
    "updated_at": "2025-06-17T14:13:04Z",
    "pushed_at": "2025-06-17T14:12:08Z",
    "size": 15940,
    "default_branch": "main",
    "html_url": "https://github.com/manasp21/MagTrace",
    "clone_url": "https://github.com/manasp21/MagTrace.git",
    "ssh_url": "git@github.com:manasp21/MagTrace.git",
    "readme_content": "# MagTrace - Magnetic Field Data Analysis Platform\n\n**Professional magnetic field analysis platform for research and industrial applications**\n\n*Author: Manas Pandey | Developed with Claude AI assistance*\n\n[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://python.org)\n[![Django](https://img.shields.io/badge/django-4.2-green.svg)](https://djangoproject.com)\n[![Status](https://img.shields.io/badge/status-development-orange.svg)](#current-limitations)\n\n## Project Status: Development Phase\n\n**Current State:** Core functionality implemented, requires comprehensive testing and production hardening.\n\nMagTrace provides magnetic field data analysis capabilities using machine learning for anomaly detection and pattern recognition. The platform processes magnetometer sensor data (B_x, B_y, B_z components) with interactive visualization and automated classification.\n\n## Quick Start\n\n```bash\ngit clone https://github.com/manasp21/MagTrace.git\ncd MagTrace\npython3 run.py\n```\n\n**Access Points:**\n- **Main Application:** http://localhost:8000/app/\n- **API Documentation:** http://localhost:8000/api/\n- **Health Check:** http://localhost:8000/health/\n\n## Core Features (Implemented)\n\n### ✅ Working Functionality\n- **Project Management** - Organize magnetic field analysis projects\n- **CSV Data Upload** - Process magnetometer readings with automatic parsing\n- **Interactive Visualization** - D3.js charts with zoom, pan, and brush selection\n- **Data Labeling** - Manual annotation of magnetic field anomalies and patterns\n- **Machine Learning Training** - Scikit-learn Random Forest classification\n- **Real-time Progress** - Live training monitoring with progress indicators\n- **RESTful API** - Complete API for programmatic access\n\n### 📊 Data Format Support\n```csv\ntimestamp_pc,b_x,b_y,b_z,lat,lon,altitude,thetax,thetay,thetaz,sensor_id\n24:40.0,7746.664,9395.448,14682.022,26.5123251,80.2238068,2018,0,0,0,S963350075783\n```\n\n**Required Columns:** `timestamp_pc`, `b_x`, `b_y`, `b_z`\n**Optional Columns:** `lat`, `lon`, `altitude`, `sensor_id`, `thetax`, `thetay`, `thetaz`\n\n## Current Limitations\n\n### 🚨 Critical Production Gaps\n\n**1. Security**\n- ❌ **No authentication system** - Single-user development setup only\n- ❌ **No input validation** - Limited CSV format checking\n- ❌ **No rate limiting** - API endpoints unprotected\n- ❌ **Insecure file uploads** - Basic validation only\n- ❌ **Debug mode enabled** - Not production-ready\n\n**2. Scalability Issues**\n- ❌ **SQLite database** - Single-user, no concurrent access\n- ❌ **File upload limits** - ~100MB maximum, no chunking\n- ❌ **Memory limitations** - Large datasets (>50k points) cause performance issues\n- ❌ **No background processing** - Training blocks server threads\n- ❌ **Single-threaded ML** - No distributed computing support\n\n**3. Data Management**\n- ❌ **No data validation** - Limited error handling for malformed CSV\n- ❌ **No backup system** - Manual database backup required\n- ❌ **No data retention** - Unlimited storage consumption\n- ❌ **No audit logging** - No tracking of data access or modifications\n\n**4. Reliability**\n- ❌ **No error recovery** - Failed operations require manual cleanup\n- ❌ **No monitoring** - No health checks or alerting\n- ❌ **Development server** - Django development server not production-ready\n- ❌ **No load balancing** - Single point of failure\n\n## Testing Requirements\n\n### 🧪 Comprehensive Testing Needed\n\n**CRITICAL:** This system requires extensive testing before any production deployment.\n\n#### Performance Testing\n- [ ] **Small datasets** (< 1,000 points) - Response time < 2 seconds\n- [ ] **Medium datasets** (1,000-10,000 points) - Memory usage < 2GB\n- [ ] **Large datasets** (> 10,000 points) - Verify decimation works correctly\n- [ ] **Concurrent users** - Test multiple simultaneous uploads\n- [ ] **Memory stress** - Monitor for memory leaks during extended use\n\n#### Functional Testing  \n- [ ] **End-to-end workflow** - Project → Upload → Label → Train → Predict\n- [ ] **API endpoints** - All CRUD operations for each model\n- [ ] **Error handling** - Invalid data, network failures, timeouts\n- [ ] **Browser compatibility** - Chrome, Firefox, Safari, Edge\n- [ ] **Data integrity** - Verify annotations persist correctly\n\n#### Security Testing\n- [ ] **Input validation** - SQL injection, XSS, file upload attacks\n- [ ] **CSRF protection** - Verify all state-changing operations protected\n- [ ] **File upload security** - Malicious file upload attempts\n- [ ] **API security** - Authentication bypass attempts\n\n#### Data Quality Testing\n- [ ] **CSV format variations** - Different timestamp formats, missing columns\n- [ ] **Magnetic field ranges** - Extreme values, negative numbers, scientific notation\n- [ ] **GPS coordinates** - Invalid lat/lon values, missing location data\n- [ ] **Large file handling** - Files approaching 100MB limit\n\n### Test Data Requirements\n\n**Minimum Test Dataset Collection:**\n1. **Small datasets** (10-100 points) - Quick validation\n2. **Medium datasets** (1,000-5,000 points) - Performance testing  \n3. **Large datasets** (10,000+ points) - Stress testing\n4. **Anomaly datasets** - Clear patterns for ML validation\n5. **Edge case datasets** - Missing values, extreme ranges, malformed data\n\n**Sample data provided:** `example/data_1.csv` (46 points) - Insufficient for comprehensive testing.\n\n## Technical Architecture\n\n### Backend Stack\n- **Framework:** Django 4.2 + Django REST Framework\n- **Database:** SQLite (development) / PostgreSQL (production required)\n- **ML Framework:** Scikit-learn 1.3.2 (TensorFlow optional, often fails)\n- **File Processing:** Pandas for CSV parsing and data manipulation\n\n### Frontend Stack  \n- **UI:** HTML5 + Vanilla JavaScript + CSS\n- **Visualization:** D3.js for interactive magnetic field charts\n- **AJAX:** Fetch API for backend communication\n\n### Key Components\n```\nbackend/\n├── magtrace_api/               # Main API application\n│   ├── models.py              # Database models (Project, Dataset, Annotation)\n│   ├── views.py               # API endpoints and business logic\n│   ├── simple_training_service.py   # ML training orchestration\n│   └── serializers.py         # API data serialization\n├── templates/magtrace.html    # Single-page application interface\n├── static/js/magtrace.js      # Frontend application logic\n└── manage.py                  # Django management commands\n```\n\n## Production Deployment Requirements\n\n### 🏭 Production Checklist\n\n**Infrastructure:**\n- [ ] **Web Server** - Nginx/Apache with WSGI (Gunicorn/uWSGI)\n- [ ] **Database** - PostgreSQL with connection pooling\n- [ ] **Caching** - Redis for session storage and API caching\n- [ ] **File Storage** - S3/MinIO for uploaded datasets (not local filesystem)\n- [ ] **Monitoring** - Application performance monitoring (APM)\n\n**Security Hardening:**\n- [ ] **Authentication** - User management system with role-based access\n- [ ] **HTTPS** - SSL certificate and secure headers\n- [ ] **Input Validation** - Comprehensive data sanitization\n- [ ] **Rate Limiting** - API request throttling\n- [ ] **File Upload Security** - Virus scanning, type validation\n\n**Scalability:**\n- [ ] **Background Jobs** - Celery + Redis for ML training\n- [ ] **Load Balancing** - Multiple application instances\n- [ ] **Database Scaling** - Read replicas, connection pooling\n- [ ] **CDN** - Static file delivery optimization\n\n**Operational:**\n- [ ] **Backup Strategy** - Automated database and file backups\n- [ ] **Logging** - Structured application and access logs\n- [ ] **Monitoring** - Health checks, error tracking, alerting\n- [ ] **Deployment Pipeline** - CI/CD with automated testing\n\n## Development Setup\n\n### Prerequisites\n- Python 3.8+ (3.10+ recommended)\n- 8GB+ RAM (for large dataset processing)\n- Modern web browser\n\n### Installation Options\n\n**1. Quick Start (Recommended)**\n```bash\npython3 run.py  # Automated setup with virtual environment\n```\n\n**2. Manual Setup**\n```bash\ncd backend\npython3 -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\n\n# Use lightweight requirements (TensorFlow often fails)\npip install -r requirements-lite.txt\n\npython manage.py migrate\npython manage.py runserver\n```\n\n### Verification\n```bash\n# Health check\ncurl http://localhost:8000/health/\n\n# Comprehensive workflow test\npython3 test_workflow.py\n```\n\n## API Overview\n\n**Core Endpoints:**\n- `POST /api/projects/` - Create magnetic field analysis project\n- `POST /api/datasets/upload/` - Upload CSV magnetometer data\n- `GET /api/datasets/{id}/data/` - Retrieve processed data with decimation\n- `POST /api/annotations/` - Create labeled data regions\n- `POST /api/training/start/` - Begin ML model training\n- `GET /api/training/status/{session_id}/` - Monitor training progress\n\n**Full API Documentation:** [docs/source/api_reference.rst](docs/source/api_reference.rst)\n\n## Known Issues\n\n### 🐛 Current Bugs\n- **Training sessions** may hang with very large datasets (>20k points)\n- **Browser performance** degrades with >50 annotations on single chart\n- **CSV parsing** fails silently with some timestamp formats\n- **Memory leaks** in long-running training sessions\n\n### ⚠️ Reliability Issues\n- **No graceful failure** handling for interrupted operations\n- **Database locks** occur with rapid successive API calls\n- **File upload** corrupts with network interruptions\n- **Training progress** not recoverable after server restart\n\n## Development Roadmap\n\n### Phase 1: Production Readiness (High Priority)\n- [ ] **Authentication system** - User registration, login, permissions\n- [ ] **Production database** - PostgreSQL migration and optimization  \n- [ ] **Security hardening** - Input validation, rate limiting, HTTPS\n- [ ] **Error handling** - Graceful failures and recovery mechanisms\n- [ ] **Unit testing** - Comprehensive test suite beyond integration tests\n\n### Phase 2: Scalability (Medium Priority)\n- [ ] **Background processing** - Celery task queue for ML training\n- [ ] **File chunking** - Large dataset upload support (>100MB)\n- [ ] **Data validation** - Robust CSV format checking and sanitization\n- [ ] **Performance optimization** - Database query optimization, caching\n\n### Phase 3: Advanced Features (Low Priority)\n- [ ] **Model export/import** - Save/load trained models\n- [ ] **Batch processing** - Multiple dataset analysis\n- [ ] **Advanced ML algorithms** - Deep learning options\n- [ ] **Real-time data streaming** - Live magnetometer data processing\n\n## Documentation\n\n**Complete Documentation:** [GitHub Pages](https://manasp21.github.io/MagTrace/docs/index.html)\n\n**Key Resources:**\n- [Installation Guide](docs/source/installation.rst) - Setup and troubleshooting\n- [Quick Start Tutorial](docs/source/quick_start_tutorial.rst) - 10-minute walkthrough\n- [API Reference](docs/source/api_reference.rst) - Complete endpoint documentation\n- [Troubleshooting Guide](docs/source/troubleshooting.rst) - Common issues and solutions\n- [Testing Results](docs/source/testing_results.rst) - Validation and performance data\n\n## Contributing\n\n**Development Environment:**\n```bash\n# Fork repository, then:\ngit clone https://github.com/YOUR_USERNAME/MagTrace.git\ncd MagTrace/backend\nsource venv/bin/activate\npip install -r requirements-lite.txt\n\n# Run tests\npython3 test_workflow.py\npython manage.py test\n```\n\n**Code Standards:**\n- Follow Django best practices for backend development\n- Use vanilla JavaScript (no framework dependencies) for frontend\n- Include docstrings for all new functions and classes\n- Add integration tests for new API endpoints\n\n## License & Attribution\n\n**Author:** Manas Pandey  \n**Development Assistance:** Claude AI (Anthropic)  \n**License:** [Specify license]\n\n---\n\n## ⚠️ Important Notice\n\n**This software is in active development and not ready for production use without significant additional work.**\n\n**For Production Deployment:**\n1. Complete comprehensive testing with your specific datasets\n2. Implement authentication and security hardening\n3. Migrate to production-grade database and infrastructure\n4. Add monitoring, logging, and backup systems\n5. Conduct security audit and penetration testing\n\n**Use in controlled environments only until production readiness checklist is completed.**",
    "cached_at": 1750765174.5735426
  },
  "https://github.com/manasp21/magnav.py": {
    "name": "magnav.py",
    "full_name": "manasp21/magnav.py",
    "description": "No description available",
    "readme_description": "MagNavPy is a Python library for magnetic navigation research and development. It is a port of the original MagNav.jl (Julia) package, providing tools for simulating magnetic navigation scenarios, ...",
    "language": "Python",
    "stars": 1,
    "forks": 0,
    "watchers": 1,
    "open_issues": 0,
    "topics": [],
    "homepage": null,
    "license": null,
    "created_at": "2025-05-27T08:29:59Z",
    "updated_at": "2025-06-06T10:09:14Z",
    "pushed_at": "2025-06-13T07:59:17Z",
    "size": 19147,
    "default_branch": "main",
    "html_url": "https://github.com/manasp21/magnav.py",
    "clone_url": "https://github.com/manasp21/magnav.py.git",
    "ssh_url": "git@github.com:manasp21/magnav.py.git",
    "readme_content": "# MagNavPy\n\n[![PyPI version](https://img.shields.io/pypi/v/magnavpy.svg)](https://pypi.org/project/magnavpy/) <!-- Placeholder -->\n[![Build Status](https://img.shields.io/travis/com/yourusername/magnavpy.svg)](https://travis-ci.com/yourusername/magnavpy) <!-- Placeholder -->\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nMagNavPy is a Python library for magnetic navigation research and development. It is a port of the original [MagNav.jl](https://github.com/MIT-AI-Accelerator/MagNav.jl) (Julia) package, providing tools for simulating magnetic navigation scenarios, processing magnetometer data, compensating for aircraft magnetic noise, and implementing navigation filters.\n\n## Key Features\n\n*   **Data Handling**: Load, process, and manage flight path, INS, and magnetometer data, including built-in datasets.\n*   **Magnetic Anomaly Maps**: Utilities for loading, manipulating (e.g., upward continuation), and interpolating magnetic anomaly maps, with access to built-in global and regional maps.\n*   **Aeromagnetic Compensation**: Implementations of classical methods like Tolles-Lawson and advanced Neural Network-based models for compensating aircraft magnetic noise.\n*   **Navigation Algorithms**: Tools for magnetic navigation filtering, including Extended Kalman Filters (EKF) and the MagNav filter model, along with performance analysis using the Cramér–Rao Lower Bound (CRLB).\n*   **Simulation & Analysis**: Simulate magnetic navigation scenarios and analyze performance.\n*   **Data Visualization**: Plotting functions to visualize flight data, magnetic maps, and filter outputs.\n\n## Core Concepts\n\nMagNavPy utilizes several key data structures to organize and manage data:\n\n*   [`Map`](magnavpy/common_types.py:9): Represents a magnetic anomaly map.\n*   [`Traj`](magnavpy/magnav.py:40): Stores flight trajectory data.\n*   [`INS`](magnavpy/magnav.py:43): Holds Inertial Navigation System data.\n*   [`XYZ`](magnavpy/magnav.py:48): A general structure for flight data including position, time, and magnetic field measurements.\n*   [`EKF_RT`](magnavpy/ekf.py:81): Represents the state of a Real-Time Extended Kalman Filter.\n*   [`CompParams`](magnavpy/compensation.py:87), [`LinCompParams`](magnavpy/compensation.py:90), [`NNCompParams`](magnavpy/compensation.py:93): Structures for holding parameters for different compensation models.\n\n## Original Project\n\nThis project is a Python conversion of the [MagNav.jl](https://github.com/MIT-AI-Accelerator/MagNav.jl) library, originally developed by the MIT AI Accelerator. We acknowledge and thank the original authors for their foundational work.\n\n## Installation\n\n### Prerequisites\n\n*   Python 3.9 or higher.\n*   **GDAL**: This library depends on GDAL.\n    *   **For Windows users:** It is strongly recommended to install GDAL using pre-compiled wheels from sources like Christoph Gohlke's Unofficial Windows Binaries for Python Extension Packages. Ensure you download the wheel compatible with your Python version (e.g., Python 3.13) and system architecture (e.g., `win_amd64`). Direct installation via `pip install gdal` can often lead to compilation issues on Windows. After downloading the appropriate `.whl` file, you can install it using pip (e.g., `pip install GDAL-3.9.0-cp313-cp313-win_amd64.whl`).\n    *   **For other operating systems:** Please refer to the [official GDAL installation guide](https://gdal.org/download.html#binaries) for instructions.\n\n### Project Dependencies\n\nBeyond the prerequisites, MagNavPy relies on several Python packages for its functionality. All required packages are listed in the [`requirements.txt`](requirements.txt:0) file and can be installed as described in the installation steps. Key dependencies include:\n\n*   **gdal**: For geospatial data operations (Python bindings, requires system-level GDAL).\n*   **pandas**: For data manipulation and analysis.\n*   **torch**: For deep learning models and tensor computations.\n*   **matplotlib**: For plotting and visualization.\n*   **h5py**: For interacting with HDF5 files.\n*   **scipy**: For scientific and technical computing.\n*   **jax**: For high-performance numerical computing and machine learning research.\n*   **toml**: For parsing TOML configuration files.\n*   **scikit-learn**: For machine learning tools.\n*   **statsmodels**: For statistical modeling.\n*   **pytest**: For running the test suite.\n\nPlease ensure GDAL is installed on your system *before* running `pip install -r requirements.txt`.\n\n### Steps\n\n1.  **Clone the repository (if you haven't already):**\n    ```bash\n    git clone https://github.com/yourusername/MagNavPy.git # Replace with actual URL\n    ```\n    Navigate into the cloned repository's root directory (where `requirements.txt` is located). All subsequent installation commands should be run from this directory.\n\n2.  **Create and activate a Python virtual environment (recommended):**\n    ```bash\n    python -m venv venv\n    # On Windows\n    # venv\\Scripts\\activate\n    # On macOS/Linux\n    source venv/bin/activate\n    ```\n\n3.  **Install dependencies:**\n    Ensure your virtual environment is active and you are in the repository root directory. To install the required Python packages, run:\n    ```bash\n    pip install -r requirements.txt\n    ```\n    If you are developing the library, you might want to install it in editable mode:\n    ```bash\n    pip install -e .\n    ```\n\n## Data and Artifact Management\n\nMagNavPy requires specific data artifacts, such as magnetic anomaly maps and flight datasets, to function correctly. Currently, these artifacts are not managed or downloaded automatically by this Python port.\n\n**Manual Placement:**\nUsers are required to manually obtain these artifacts and place them in a directory named `artifacts_data`. This directory should be located at the **root of the `MagNavPy` repository** (e.g., if you cloned the repository into a folder named `MagNavPy`, the path would be `MagNavPy/artifacts_data/`).\n\n**Obtaining Artifacts:**\nInformation regarding the required artifacts and their original sources can be found in the [`Artifacts.toml`](../MagNav.jl/Artifacts.toml:1) file of the original [MagNav.jl project](https://github.com/MIT-AI-Accelerator/MagNav.jl/blob/main/Artifacts.toml). Please refer to this file to identify and download the necessary data.\n\n## Usage\n\nMagNavPy provides functions for various stages of magnetic navigation processing. Here are examples of key functions:\n\n**Data Loading:**\nUse functions like [`create_xyz0`](magnavpy/create_xyz.py:9), [`get_xyz20`](magnavpy/create_xyz.py:11), or [`get_XYZ`](magnavpy/create_xyz.py:13) to load flight data. Built-in datasets like `sgl_2020_train` and `sgl_2021_train` are also available.\n\n**Map Handling:**\nLoad magnetic anomaly maps using [`get_map`](magnavpy/map_utils.py:9). Functions like [`upward_fft`](magnavpy/map_utils.py:25) are available for map manipulation.\n\n**Aeromagnetic Compensation:**\nTrain and test compensation models using [`comp_train`](magnavpy/compensation.py:16) and [`comp_test`](magnavpy/compensation.py:21). The library supports classical Tolles-Lawson and various Neural Network-based models (e.g., `:m1`, `:m2a`, `:m2b`, `:m2c`, `:m2d`, `:m3s`, `:m3v`).\n\n**Navigation Filtering:**\nRun navigation filters, such as the Extended Kalman Filter, using the [`run_filt`](magnavpy/magnav.py:33) function.\n\nFor more detailed examples, please refer to the `examples/` directory (if available) or the test scripts in the `tests/` directory.\n\n## Documentation\n\nFull documentation, including API references and usage guides, is generated using Sphinx.\n\nTo build the documentation locally:\n```bash\ncd docs\nmake html\n```\nThen, open `docs/build/html/index.html` in your web browser.\n\nThe documentation may also be hosted online in the future.\n\n## Testing\n\nTo run the test suite, navigate to the root directory of the project and use `pytest`:\n```bash\npytest tests/\n```\nThis will execute all tests defined in the `tests/` directory.\n\n## Current Status and Known Issues\n\nThis Python port of MagNav.jl is an ongoing development effort. While significant progress has been made, users should be aware of the following:\n\n*   **Ongoing Porting:** The library is actively being ported from Julia. Not all features and functionalities of the original MagNav.jl may be fully implemented or tested.\n*   **Environment and Imports:** Initial challenges with setting up the Python environment, particularly GDAL installation and resolving relative import paths within the `magnavpy` package, have been largely addressed.\n*   **Testing Coverage:** The original task mentioned \"pytest errors and otherwise.\" A comprehensive review and execution of the `pytest` test suite to ensure full functionality and identify remaining issues is still pending.\n*   **Manual Data Artifacts:** As detailed in the \"Data and Artifact Management\" section, data artifacts are currently handled manually. There is no automated download or management system within this Python port.\n*   **Documentation:** Documentation is being actively developed. While Sphinx documentation is available, it may not yet cover all aspects of the Python port comprehensively.\n\n## Contributing\n\nContributions are welcome! If you'd like to contribute, please feel free to open an issue to discuss your ideas or submit a pull request.\n(More detailed contribution guidelines may be added to a `CONTRIBUTING.md` file in the future.)\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details (assuming a `LICENSE` file will be added, or state \"MIT License\" directly). The original MagNav.jl project is also licensed under the MIT License.\n\n## Acknowledgements\n\n*   The developers and contributors of the original [MagNav.jl](https://github.com/MIT-AI-Accelerator/MagNav.jl).\n*   The broader open-source community for the tools and libraries that make this project possible.",
    "cached_at": 1750765177.8482242
  }
}